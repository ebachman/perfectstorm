#!/usr/bin/env python3

import gevent.monkey
gevent.monkey.patch_all()
# Prevent 'KeyboardInterrupt' lines from being printed
# on standard error
gevent.get_hub().NOT_ERROR += (KeyboardInterrupt,)

import collections  # noqa: E402
import functools  # noqa: E402
import re  # noqa: E402
import shlex  # noqa: E402
import subprocess  # noqa: E402
import urllib.parse  # noqa: E402
import yaml  # noqa: E402

import requests  # noqa: E402

from stormlib import Agent, Resource, Group, events  # noqa: E402
from stormlib.cli import AgentClient  # noqa: E402
from stormlib.exceptions import (  # noqa: E402
    StormBadRequestError, StormValidationError)
from stormlib.executors import (  # noqa: E402
    PollingExecutor,
    AgentExecutorMixin,
    DiscoveryExecutor,
    DiscoveryProbe,
    GeventJobsExecutor,
    GeventPipelineExecutor,
    ProcedureExecutor,
    ProcedureRunner,
)


IMAGE_REGEX = re.compile(
    r'^(?:([^/:@]+)/)?([^/:@]+)(?::([^/:@]+))?(?:@([^/@]+))?$')


def canonical_image_name(image):
    match = IMAGE_REGEX.match(image)
    repository, name, tag, digest = match.groups()

    if not repository:
        repository = 'library'
    if not tag:
        tag = 'latest'

    image = '{}/{}:{}'.format(repository, name, tag)

    if digest:
        image += '@' + digest

    return image


class Swarm:

    def __init__(self, address):
        self.address = address
        self._cluster_id = None

    def get(self, path):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.get(url)
        response.raise_for_status()
        return response

    def post(self, path, **kwargs):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.post(url, **kwargs)
        response.raise_for_status()
        return response

    @property
    def cluster_id(self):
        if self._cluster_id is None:
            data = self.get('info').json()
            self._cluster_id = data['Swarm']['Cluster']['ID']
        return self._cluster_id


class SwarmMixin:

    def __init__(self, swarm, *args, **kwargs):
        self.swarm = swarm
        super().__init__(*args, **kwargs)


class SwarmProcedureRunner(SwarmMixin, ProcedureRunner):

    def run(self):
        for args in self.list_commands():
            self.run_command(args)

    def list_commands(self):
        commands = yaml.load(self.job.content)
        if not isinstance(commands, list):
            raise StormValidationError(
                'expected a list of commands')

        result = []

        for args in commands:
            if isinstance(args, str):
                args = shlex.split(args)
            if (not isinstance(args, list) or
                    not all(isinstance(arg, str) for arg in args)):
                raise StormValidationError(
                    'each command must be a string or a list of strings')
            result.append(args)

        return result

    def run_command(self, args):
        args = ['docker', '--host', self.swarm.address, *args]
        subprocess.run(args, input=b'', check=True)


class SwarmProcedureExecutor(
        SwarmMixin, ProcedureExecutor, GeventJobsExecutor):

    def get_pending_jobs(self):
        qs = super().get_pending_jobs()
        return qs.filter(target=self.swarm.cluster_id)

    def get_procedure_runner(self, agent, job):
        return SwarmProcedureRunner(self.swarm, agent, job)


class SwarmClusterProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-cluster'

    def get_snapshots(self):
        data = self.swarm.get('info').json()
        # Remove SystemTime to avoid unnecessary updates
        del data['SystemTime']
        return [data]

    def get_internal_id(self, data):
        return data['Swarm']['Cluster']['ID']

    def model_resource(self, data):
        return Resource(
            names=[
                data['Swarm']['Cluster']['Spec']['Name'],
                data['Swarm']['Cluster']['ID'],
            ],
            status='running',
        )


class SwarmServiceProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-service'

    def get_snapshots(self):
        return self.swarm.get('services').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_service_names(self, data):
        return [
            data['Spec']['Name'],
            data['ID'],
        ]

    def get_service_image(self, data):
        return canonical_image_name(
            data['Spec']['TaskTemplate']['ContainerSpec']['Image'])

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            names=self.get_service_names(data),
            image=self.get_service_image(data),
            status='running',
        )


class SwarmTaskProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-task'

    def __init__(self, executor, *args, **kwargs):
        self.executor = executor
        super().__init__(*args, **kwargs)

    def get_snapshots(self):
        return self.swarm.get('tasks').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_task_names(self, data):
        names = []

        try:
            service_id = data['ServiceID']
            service_data = self.executor.snapshots[service_id].data
            service_name = service_data['Spec']['Name']
        except KeyError:
            service_name = None

        if service_name:
            task_name_suffix = (
                str(data['Slot']) if 'Slot' in data else data['NodeID'])
            task_name = '.'.join((service_name, task_name_suffix))

            names.append(task_name)
            names.append('.'.join((task_name, data['ID'])))

        names.append(data['ID'])

        try:
            names.append(data['Status']['ContainerStatus']['ContainerID'])
        except KeyError:
            pass

        return names

    def get_task_image(self, data):
        return canonical_image_name(data['Spec']['ContainerSpec']['Image'])

    def get_task_status(self, data):
        docker2storm_status = {
            'new': 'created',
            'allocated': 'created',
            'pending': 'starting',
            'assigned': 'starting',
            'accepted': 'starting',
            'preparing': 'starting',
            'ready': 'starting',
            'starting': 'starting',
            'running': 'running',
            'complete': 'stopped',
            'shutdown': 'stopped',
            'failed': 'error',
            'rejected': 'error',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def get_task_health(self, data):
        if ('Healthcheck' in data['Spec']['ContainerSpec'] and
                data['Status']['State'] == 'running'):
            # If a task has health checks configured and it is running, it
            # means it is healthy. If the health checks were reporting errors,
            # then Swarm would automatically restart the task.
            return 'healthy'
        return 'unknown'

    def model_resource(self, data):
        return Resource(
            parent=data['ServiceID'],
            names=self.get_task_names(data),
            image=self.get_task_image(data),
            status=self.get_task_status(data),
            health=self.get_task_health(data),
        )

    def save_resource(self, resource):
        try:
            resource.save()
        except StormBadRequestError:
            # It can happen that some tasks have a ServiceID field, but
            # the corresponding service has been deleted. This situation
            # may occur, for example, after deleing a service: the service
            # itself is gone, but its tasks still need to be removed.
            #
            # In such situation, the Storm API Server will complain that
            # 'parent' does not reference a Resource and will refuse to
            # save the task with a StormBadRequestError. For this reason,
            # we try again, this time unsetting the 'parent' field.
            if resource.parent is None:
                raise
            resource.parent = None
            resource.save()


class SwarmNodeProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-node'

    def get_snapshots(self):
        return self.swarm.get('nodes').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_node_names(self, data):
        return [
            data['Description']['Hostname'],
            data['ID'],
        ]

    def get_node_status(self, data):
        docker2storm_status = {
            'disconnected': 'stopped',
            'down': 'stopped',
            'ready': 'running',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def get_node_health(self, data):
        reachability2health = {
            'reachable': 'healthy',
            'unreachable': 'unhealthy',
        }

        try:
            return reachability2health[data['ManagerStatus']['Reachability']]
        except KeyError:
            return 'unknown'

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            names=[
                data['Description']['Hostname'],
                data['ID'],
            ],
            status=self.get_node_status(data),
            health=self.get_node_health(data),
        )


class SwarmDiscoveryExecutor(SwarmMixin, DiscoveryExecutor):

    def get_probes(self):
        return [
            SwarmClusterProbe(self.swarm),
            SwarmServiceProbe(self.swarm),
            SwarmTaskProbe(self, self.swarm),
            SwarmNodeProbe(self.swarm),
        ]


class SwarmNodeLabelingExecutor(
        SwarmMixin, AgentExecutorMixin, PollingExecutor, GeventJobsExecutor):

    # XXX It is possible to create groups with a query that excludes
    # XXX members of the group itself. Example:
    # XXX
    # XXX   group:
    # XXX     query:
    # XXX       snapshot.Spec.Labels.storm-grouped: { $exists: false }
    # XXX
    # XXX This will result in an infinite label/unlabel loop:
    # XXX
    # XXX - during the first iteration, all resources without a
    # XXX   'storm-grouped' label will be labelled;
    # XXX - at the second iteration the same resources will be no
    # XXX   longer part of the group, and will lose their label;
    # XXX - at this point we are back to our initial conditions:
    # XXX   the label will be applied again, then removed, and so on...

    def get_labeling(self):
        resources = {}
        labels = collections.defaultdict(dict)

        named_groups = Group.objects.filter(name={'$exists': True})

        for group in named_groups:
            relevant_members = group.members().filter(
                type={'$in': ('swarm-service', 'swarm-node')},
                owner=self.agent.id,
            )

            for resource in relevant_members:
                labels[resource.id]['storm-grouped'] = 'yes'
                labels[resource.id]['storm-group-' + group.name] = 'yes'
                resources[resource.id] = resource

        # Get all the resources that have 'storm-grouped' label, but that
        # do not belong to any group. Those will have their label removed.
        extra_labels = Resource.objects.filter(**{
            'id': {'$nin': list(labels)},
            'type': {'$in': ('swarm-service', 'swarm-node')},
            'owner': self.agent.id,
            'snapshot.Spec.Labels.storm-grouped': {'$exists': True},
        })

        for resource in extra_labels:
            labels[resource.id] = {}
            resources[resource.id] = resource

        return [
            (resources[res_id], res_labels)
            for res_id, res_labels in labels.items()
            if self.labels_changed(resources[res_id], res_labels)
        ]

    def labels_changed(self, resource, new_labels):
        old_labels = resource.snapshot['Spec']['Labels']
        old_labels = {
            key: value for key, value in old_labels.items()
            if key.startswith('storm-group')
        }
        return old_labels != new_labels

    def poll_jobs(self):
        event_filter = events.EventFilter([
            events.EventMask(event_type='created', entity_type='resource'),
            events.EventMask(event_type='updated', entity_type='resource'),
            events.EventMask(event_type='created', entity_type='group'),
            events.EventMask(event_type='updated', entity_type='group'),
            events.EventMask(event_type='deleted', entity_type='group'),
        ])

        with event_filter(events.stream()) as stream:
            while True:
                labeling = self.get_labeling()
                if labeling:
                    break
                next(stream)

        return [
            functools.partial(self.assign_labels, *args)
            for args in labeling
        ]

    def assign_labels(self, resource, labels):
        spec = resource.snapshot['Spec']
        old_labels = spec['Labels']

        new_labels = {
            key: value for key, value in old_labels.items()
            if not key.startswith('storm-group')
        }
        new_labels.update(labels)

        spec['Labels'] = new_labels

        if resource.type == 'swarm-service':
            update_type = 'services'
        elif resource.type == 'swarm-node':
            update_type = 'nodes'
        else:
            raise RuntimeError(resource.type)

        update_id = urllib.parse.quote(resource.snapshot['ID'])
        update_version = resource.snapshot['Version']['Index']

        self.swarm.post(
            '{}/{}/update'.format(update_type, update_id),
            params={'version': update_version},
            json=spec)


class SwarmClient(AgentClient):

    def add_arguments(self, parser):
        super().add_arguments(parser)
        parser.add_argument(
            '-H', '--host', metavar='HOST[:PORT]', required=True,
            help='Docker daemon to connect to')
        parser.add_argument(
            '-p', '--with-procedure-runner', action='store_true',
            help='Run Swarm procedures submitted to this cluster')
        parser.add_argument(
            '-l', '--with-auto-labeling', action='store_true',
            help='Enable automatic labeling of services and nodes')

    def get_agent(self):
        self.swarm = Swarm(self.options.host)

        data = self.swarm.get('info').json()
        cluster_id = data['Swarm']['Cluster']['ID']

        return Agent(
            type='swarm',
            name='swarm-' + cluster_id,
            options={
                'autoLabeling': self.options.with_auto_labeling,
                'procedureRunner': self.options.with_procedure_runner,
            },
        )

    def run(self):
        jobs = [
            SwarmDiscoveryExecutor(swarm=self.swarm, agent=self.agent),
        ]

        if self.options.with_procedure_runner:
            jobs.append(SwarmProcedureExecutor(
                swarm=self.swarm, agent=self.agent))

        if self.options.with_auto_labeling:
            jobs.append(SwarmNodeLabelingExecutor(
                swarm=self.swarm, agent=self.agent))

        executor = GeventPipelineExecutor(jobs=jobs, restart_jobs=True)
        executor()


if __name__ == '__main__':
    SwarmClient().main()
