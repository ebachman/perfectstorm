#!/usr/bin/env python3

import gevent.monkey
gevent.monkey.patch_all()
# Prevent 'KeyboardInterrupt' lines from being printed
# on standard error
gevent.get_hub().NOT_ERROR += (KeyboardInterrupt,)

import argparse  # noqa: E402
import collections  # noqa: E402
import functools  # noqa: E402
import io  # noqa: E402
import json  # noqa: E402
import logging  # noqa: E402
import re  # noqa: E402
import shlex  # noqa: E402
import subprocess  # noqa: E402
import textwrap  # noqa: E402
import urllib.parse  # noqa: E402
import yaml  # noqa: E402

import requests  # noqa: E402

from stormlib import Agent, Resource, Group, events  # noqa: E402
from stormlib.cli import AgentClient  # noqa: E402
from stormlib.exceptions import (  # noqa: E402
    StormBadRequestError, StormValidationError, StormObjectNotFound)
from stormlib.executors import (  # noqa: E402
    PollingExecutor,
    AgentExecutorMixin,
    DiscoveryExecutor,
    DiscoveryProbe,
    GeventJobsExecutor,
    GeventPipelineExecutor,
    ProcedureExecutor,
    ProcedureRunner,
)

log = logging.getLogger(__name__)

IMAGE_REGEX = re.compile(
    r'^(?:([^/:@]+)/)?([^/:@]+)(?::([^/:@]+))?(?:@([^/@]+))?$')


def run_subprocess(args):
    sh_command = ' '.join(shlex.quote(arg) for arg in args)

    try:
        proc = subprocess.run(
            args,
            input=b'',
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            check=True)
    except subprocess.CalledProcessError as exc:
        output = '\n' + exc.output if exc.output else ''
        log.debug(
            'Command exited with status %s:\n%s%s',
            exc.returncode, sh_command, output)
        raise

    output = '\n' + proc.stdout if proc.stdout else ''
    log.debug('%s%s', sh_command, output)

    return proc


def canonical_image_name(image):
    match = IMAGE_REGEX.match(image)
    repository, name, tag, digest = match.groups()

    parts = []

    if repository and repository != 'library':
        parts += [repository, '/']

    parts += [name, ':', tag or 'latest']

    if digest:
        parts += ['@', digest]

    return ''.join(parts)


class Swarm:

    def __init__(self, address):
        self.address = address
        self._cluster_id = None

    def get(self, path):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.get(url)
        response.raise_for_status()
        return response

    def post(self, path, **kwargs):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.post(url, **kwargs)
        response.raise_for_status()
        return response

    @property
    def cluster_id(self):
        if self._cluster_id is None:
            data = self.get('info').json()
            self._cluster_id = data['Swarm']['Cluster']['ID']
        return self._cluster_id


class SwarmMixin:

    def __init__(self, swarm, *args, **kwargs):
        self.swarm = swarm
        super().__init__(*args, **kwargs)


class SwarmServiceExecEmulator(SwarmMixin):

    SHELL_SCRIPT_TEMPLATE = textwrap.dedent('''\
        post() {{
          curl -s --unix-socket /var/run/docker.sock \\
            -H 'Content-Type: application/json' \\
            -d "$1" "http://localhost/$2"
        }}
        post {exec_data} "containers/{container_id}/exec"
        exec_id=$(post {exec_data} "containers/{container_id}/exec" | \\
            grep -Eo '\\<[0-9a-f]{{64}}\\>')
        post {start_data} "exec/$exec_id/start"
    ''').strip()

    def __init__(self, swarm, args):
        super().__init__(swarm)
        self.parse_args(args)

    def parse_args(self, args):
        output = io.StringIO()

        class ArgumentParser(argparse.ArgumentParser):

            def _print_message(self, message, file=None):
                if message:
                    output.write(message)

        parser = ArgumentParser()

        parser.add_argument('-d', '--detach', action='store_true')
        parser.add_argument('-e', '--env', action='append')
        parser.add_argument('--privileged', action='store_true')
        parser.add_argument('-u', '--user')
        parser.add_argument('-w', '--workdir')
        parser.add_argument('task')
        parser.add_argument('command')

        try:
            self.options, extra_args = parser.parse_known_args(args)
        except SystemExit as exc:
            raise subprocess.CalledProcessError(
                returncode=exc.code, cmd=args, output=output.getvalue())

        self.options.args = extra_args

        self.task = Resource.objects.get(
            type='swarm-task',
            names=self.options.task,
            cluster=self.swarm.cluster_id)
        self.node = Resource.objects.get(self.task.host)

    def get_create_command(self):
        container_id = (
            self.task.snapshot['Status']['ContainerStatus']['ContainerID'])

        exec_data = json.dumps({
            'AttachStdin': False,
            'AttachStdout': False,
            'AttachStderr': False,
            'Tty': False,
            'Cmd': [
                self.options.command,
                *self.options.args,
            ],
            'Env': self.options.env,
            'Privileged': self.options.privileged,
            'User': self.options.user,
            'WorkingDir': self.options.workdir,
        })

        start_data = json.dumps({
            'Detach': self.options.detach,
            'Tty': False,
        })

        shell_script = self.SHELL_SCRIPT_TEMPLATE.format(
            container_id=shlex.quote(container_id),
            exec_data=shlex.quote(exec_data),
            start_data=shlex.quote(start_data),
        )

        return [
            'docker',
            '--host', self.swarm.address,
            'service', 'create',
            '--detach',
            '--restart-condition', 'none',
            '--constraint', 'node.id==' + self.node.snapshot['ID'],
            '--mount',
            'type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock',
            '--label', 'storm-swarm-exec=yes',
            '--label', 'storm-swarm-exec-task=' + self.options.task,
            '--label', 'storm-swarm-exec-command=' + self.options.command,
            'appropriate/curl',
            'sh', '-euc', shell_script,
        ]

    def get_remove_command(self, service_id):
        return [
            'docker',
            '--host', self.swarm.address,
            'service', 'rm', service_id,
        ]

    def run(self):
        create_cmd = self.get_create_command()

        with events.stream() as event_stream:
            proc = run_subprocess(create_cmd)
            service_id = proc.stdout.strip()
            self.wait(service_id, event_stream)

        rm_cmd = self.get_remove_command(service_id)
        run_subprocess(rm_cmd)

    def wait(self, service_id, event_stream):
        # Wait for the helper service to appear
        event_filter = events.EventFilter([
            events.EventMask('created', 'resource', None, [service_id]),
        ])
        event_stream = event_filter(event_stream)
        for event in event_stream:
            helper_service = event.entity.retrieve()
            break

        # Wait for the helper task to appear
        event_filter.clear()
        event_filter.register_all([
            events.EventMask('created', 'resource'),
            events.EventMask('updated', 'resource', helper_service.id),
            events.EventMask('deleted', 'resource', helper_service.id),
        ])
        for event in event_stream:
            try:
                resource = event.entity.retrieve()
            except StormObjectNotFound:
                return
            if (resource.type == 'swarm-task' and
                    resource.parent == helper_service.id):
                helper_task = resource
                break

        # Check if the task is complete
        if helper_task.status in ('stopped', 'error'):
            return

        # Wait for the helper task to complete
        event_filter.clear()
        event_filter.register_all([
            events.EventMask('updated', 'resource', helper_task.id),
            events.EventMask('deleted', 'resource', helper_task.id),
        ])
        for event in event_stream:
            try:
                helper_task.reload()
            except StormObjectNotFound:
                return
            if helper_task.status in ('stopped', 'error'):
                return


class SwarmProcedureRunner(SwarmMixin, ProcedureRunner):

    def run(self):
        outputs = []

        try:
            for args in self.list_commands():
                outputs.append(self.run_command(args))
        except subprocess.CalledProcessError as exc:
            outputs.append(exc.output)
            self.fail({'outputs': outputs})
        else:
            self.complete({'outputs': outputs})

    def list_commands(self):
        commands = yaml.load(self.job.content)
        if not isinstance(commands, list):
            raise StormValidationError(
                'expected a list of commands')

        result = []

        for args in commands:
            if isinstance(args, str):
                args = shlex.split(args)
            if (not isinstance(args, list) or
                    not all(isinstance(arg, str) for arg in args)):
                raise StormValidationError(
                    'each command must be a string or a list of strings')
            result.append(args)

        return result

    def run_command(self, args):
        log.debug('Executing: %s', ' '.join(shlex.quote(arg) for arg in args))

        if args[:2] == ['service', 'exec']:
            emulator = SwarmServiceExecEmulator(self.swarm, args[2:])
            return emulator.run()

        proc = run_subprocess(['docker', '--host', self.swarm.address, *args])
        return proc.stdout


class SwarmProcedureExecutor(
        SwarmMixin, ProcedureExecutor, GeventJobsExecutor):

    procedure_type = 'swarm'

    def get_pending_jobs(self):
        qs = super().get_pending_jobs()
        return qs.filter(target=self.swarm.cluster_id)

    def get_procedure_runner(self, agent, job):
        return SwarmProcedureRunner(self.swarm, agent, job)


class SwarmClusterProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-cluster'

    def get_snapshots(self):
        data = self.swarm.get('info').json()
        # Remove SystemTime to avoid unnecessary updates
        del data['SystemTime']
        return [data]

    def get_internal_id(self, data):
        return data['Swarm']['Cluster']['ID']

    def model_resource(self, data):
        return Resource(
            names=[
                data['Swarm']['Cluster']['Spec']['Name'],
                data['Swarm']['Cluster']['ID'],
            ],
            status='running',
        )


class SwarmServiceProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-service'

    def get_snapshots(self):
        return self.swarm.get('services').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_service_names(self, data):
        return [
            data['Spec']['Name'],
            data['ID'],
        ]

    def get_service_image(self, data):
        return canonical_image_name(
            data['Spec']['TaskTemplate']['ContainerSpec']['Image'])

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            cluster=self.swarm.cluster_id,
            names=self.get_service_names(data),
            image=self.get_service_image(data),
            status='running',
        )


class SwarmTaskProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-task'

    def __init__(self, executor, *args, **kwargs):
        self.executor = executor
        super().__init__(*args, **kwargs)

    def get_snapshots(self):
        return self.swarm.get('tasks').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_task_names(self, data):
        names = []

        try:
            service_id = data['ServiceID']
            service_data = self.executor.snapshots[service_id].data
            service_name = service_data['Spec']['Name']
        except KeyError:
            service_name = None

        if service_name:
            task_name_suffix = (
                str(data['Slot']) if 'Slot' in data else data['NodeID'])
            task_name = '.'.join((service_name, task_name_suffix))

            names.append(task_name)
            names.append('.'.join((task_name, data['ID'])))

        names.append(data['ID'])

        try:
            names.append(data['Status']['ContainerStatus']['ContainerID'])
        except KeyError:
            pass

        return names

    def get_task_image(self, data):
        return canonical_image_name(data['Spec']['ContainerSpec']['Image'])

    def get_task_status(self, data):
        # Map the 'swarm state' to ('state', 'transitioning state').
        # 'state' is used when state == desired_state (see below).
        # 'transitioning state' is used when state != desired_state, i.e.
        # when Swarm has to change from a state to another.
        status_map = {
            'new': 'created',
            'allocated': 'created',
            'pending': 'starting',
            'assigned': 'starting',
            'accepted': 'starting',
            'preparing': 'starting',
            'ready': 'starting',
            'starting': 'starting',
            'running': 'running',
            'complete': 'stopped',
            'shutdown': 'stopped',
            'failed': 'error',
            'rejected': 'error',
            'remove': 'stopped',
            'orphaned': 'error',
        }

        try:
            status = status_map[data['Status']['State']]
            desired_status = status_map[data['DesiredState']]
        except KeyError:
            return 'unknown'

        if status == desired_status or status == 'error':
            return status

        transitions = {
            'created': 'creating',
            'started': 'starting',
            'stopped': 'stopping',
        }

        return transitions.get(desired_status, desired_status)

    def get_task_health(self, data):
        if ('Healthcheck' in data['Spec']['ContainerSpec'] and
                data['Status']['State'] == 'running'):
            # If a task has health checks configured and it is running, it
            # means it is healthy. If the health checks were reporting errors,
            # then Swarm would automatically restart the task.
            return 'healthy'
        return 'unknown'

    def model_resource(self, data):
        return Resource(
            parent=data['ServiceID'],
            cluster=self.swarm.cluster_id,
            host=data.get('NodeID'),
            names=self.get_task_names(data),
            image=self.get_task_image(data),
            status=self.get_task_status(data),
            health=self.get_task_health(data),
        )

    def save_resource(self, resource):
        try:
            resource.save()
        except StormBadRequestError:
            # It can happen that some tasks have a ServiceID field, but
            # the corresponding service has been deleted. This situation
            # may occur, for example, after deleing a service: the service
            # itself is gone, but its tasks still need to be removed.
            #
            # In such situation, the Storm API Server will complain that
            # 'parent' does not reference a Resource and will refuse to
            # save the task with a StormBadRequestError. For this reason,
            # we try again, this time unsetting the 'parent' field.
            if resource.parent is None:
                raise
            resource.parent = None
            resource.save()


class SwarmNodeProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-node'

    def get_snapshots(self):
        return self.swarm.get('nodes').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_node_names(self, data):
        return [
            data['Description']['Hostname'],
            data['ID'],
        ]

    def get_node_status(self, data):
        docker2storm_status = {
            'disconnected': 'stopped',
            'down': 'stopped',
            'ready': 'running',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def get_node_health(self, data):
        reachability2health = {
            'reachable': 'healthy',
            'unreachable': 'unhealthy',
        }

        try:
            return reachability2health[data['ManagerStatus']['Reachability']]
        except KeyError:
            return 'unknown'

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            cluster=self.swarm.cluster_id,
            names=[
                data['Description']['Hostname'],
                data['ID'],
            ],
            status=self.get_node_status(data),
            health=self.get_node_health(data),
        )


class SwarmDiscoveryExecutor(SwarmMixin, DiscoveryExecutor):

    def get_probes(self):
        return [
            SwarmClusterProbe(self.swarm),
            SwarmNodeProbe(self.swarm),
            SwarmServiceProbe(self.swarm),
            SwarmTaskProbe(self, self.swarm),
        ]


class SwarmNodeLabelingExecutor(
        SwarmMixin, AgentExecutorMixin, PollingExecutor, GeventJobsExecutor):

    # XXX It is possible to create groups with a query that excludes
    # XXX members of the group itself. Example:
    # XXX
    # XXX   group:
    # XXX     query:
    # XXX       snapshot.Spec.Labels.storm-grouped: { $exists: false }
    # XXX
    # XXX This will result in an infinite label/unlabel loop:
    # XXX
    # XXX - during the first iteration, all resources without a
    # XXX   'storm-grouped' label will be labelled;
    # XXX - at the second iteration the same resources will be no
    # XXX   longer part of the group, and will lose their label;
    # XXX - at this point we are back to our initial conditions:
    # XXX   the label will be applied again, then removed, and so on...

    def get_labeling(self):
        resources = {}
        labels = collections.defaultdict(dict)

        named_groups = Group.objects.filter(name={'$exists': True})

        for group in named_groups:
            relevant_members = group.members().filter(
                type={'$in': ('swarm-service', 'swarm-node')},
                owner=self.agent.id,
            )

            for resource in relevant_members:
                labels[resource.id]['storm-grouped'] = 'yes'
                labels[resource.id]['storm-group-' + group.name] = 'yes'
                resources[resource.id] = resource

        # Get all the resources that have 'storm-grouped' label, but that
        # do not belong to any group. Those will have their label removed.
        extra_labels = Resource.objects.filter(**{
            'id': {'$nin': list(labels)},
            'type': {'$in': ('swarm-service', 'swarm-node')},
            'owner': self.agent.id,
            'snapshot.Spec.Labels.storm-grouped': {'$exists': True},
        })

        for resource in extra_labels:
            labels[resource.id] = {}
            resources[resource.id] = resource

        return [
            (resources[res_id], res_labels)
            for res_id, res_labels in labels.items()
            if self.labels_changed(resources[res_id], res_labels)
        ]

    def labels_changed(self, resource, new_labels):
        old_labels = resource.snapshot['Spec']['Labels']
        old_labels = {
            key: value for key, value in old_labels.items()
            if key.startswith('storm-group')
        }
        return old_labels != new_labels

    def poll_jobs(self):
        filters = [
            'created:resource',
            'updated:resource',
            'created:group',
            'updated:group',
            'deleted:group',
        ]

        with events.stream(filters) as stream:
            while True:
                labeling = self.get_labeling()
                if labeling:
                    break
                next(stream)

        return [
            functools.partial(self.assign_labels, *args)
            for args in labeling
        ]

    def assign_labels(self, resource, labels):
        if labels:
            log.debug(
                'Adding labels to %s %s: %s',
                resource.type, resource.id, ', '.join(labels.keys()))
        else:
            log.debug(
                'Removing labels from %s %s',
                resource.type, resource.id)

        spec = resource.snapshot['Spec']
        old_labels = spec['Labels']

        new_labels = {
            key: value for key, value in old_labels.items()
            if not key.startswith('storm-group')
        }
        new_labels.update(labels)

        spec['Labels'] = new_labels

        if resource.type == 'swarm-service':
            update_type = 'services'
        elif resource.type == 'swarm-node':
            update_type = 'nodes'
        else:
            raise RuntimeError(resource.type)

        update_id = urllib.parse.quote(resource.snapshot['ID'])
        update_version = resource.snapshot['Version']['Index']

        self.swarm.post(
            '{}/{}/update'.format(update_type, update_id),
            params={'version': update_version},
            json=spec)


class SwarmClient(AgentClient):

    configure_loggers = [__name__]

    def add_arguments(self, parser):
        super().add_arguments(parser)
        parser.add_argument(
            '-H', '--host', metavar='HOST[:PORT]', required=True,
            help='Docker daemon to connect to')
        parser.add_argument(
            '-f', '--force-discovery', action='store_true',
            help='Ignore resources already discovered')
        parser.add_argument(
            '-p', '--with-procedure-runner', action='store_true',
            help='Run Swarm procedures submitted to this cluster')
        parser.add_argument(
            '-l', '--with-auto-labeling', action='store_true',
            help='Enable automatic labeling of services and nodes')

    def get_agent(self):
        self.swarm = Swarm(self.options.host)

        data = self.swarm.get('info').json()
        cluster_id = data['Swarm']['Cluster']['ID']

        return Agent(
            type='swarm',
            name='swarm-' + cluster_id,
            options={
                'autoLabeling': self.options.with_auto_labeling,
                'procedureRunner': self.options.with_procedure_runner,
            },
        )

    def run(self):
        log.info('storm-swarm version 0.1')
        log.info('Docker Swarm: {}'.format(self.swarm.address))

        jobs = [
            SwarmDiscoveryExecutor(
                swarm=self.swarm, agent=self.agent,
                delete_stored=self.options.force_discovery),
        ]

        if self.options.with_procedure_runner:
            jobs.append(SwarmProcedureExecutor(
                swarm=self.swarm, agent=self.agent))

        if self.options.with_auto_labeling:
            jobs.append(SwarmNodeLabelingExecutor(
                swarm=self.swarm, agent=self.agent))

        executor = GeventPipelineExecutor(jobs=jobs, restart_jobs=True)
        executor()


if __name__ == '__main__':
    SwarmClient().main()
