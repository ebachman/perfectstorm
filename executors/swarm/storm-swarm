#!/usr/bin/env python3

import gevent.monkey
gevent.monkey.patch_all()
# Prevent 'KeyboardInterrupt' lines from being printed
# on standard error
gevent.get_hub().NOT_ERROR += (KeyboardInterrupt,)

import re  # noqa: E402
import shlex  # noqa: E402
import subprocess  # noqa: E402

import requests  # noqa: E402

from stormlib import Agent, Resource  # noqa: E402
from stormlib.cli import AgentClient  # noqa: E402
from stormlib.exceptions import StormValidationError  # noqa: E402
from stormlib.executors import (  # noqa: E402
    DiscoveryExecutor,
    DiscoveryProbe,
    GeventJobsExecutor,
    GeventPipelineExecutor,
    ProcedureExecutor,
    ProcedureRunner,
)


_var_re = re.compile(r'(?<!\$)\$(\w+|{[^}]*})')
_image_re = re.compile(r'^(?:([^/:@]+)/)?([^/:@]+)(?::([^/:@]+))?(?:@([^/@]+))?$')


class Swarm:

    def __init__(self, address):
        self.address = address
        self._cluster_id = None

    def get_json(self, path):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.get(url)
        response.raise_for_status()
        return response.json()

    @property
    def cluster_id(self):
        if self._cluster_id is None:
            data = self.get_json('info')
            self._cluster_id = data['Swarm']['Cluster']['ID']
        return self._cluster_id


class SwarmMixin:

    def __init__(self, swarm, *args, **kwargs):
        self.swarm = swarm
        super().__init__(*args, **kwargs)


class DockerCommand(SwarmMixin):

    def __init__(self, swarm, args):
        super().__init__(swarm=swarm)

        var = None
        err = False

        if isinstance(args, dict):
            if len(args) == 1:
                var, args = args.popitem()

        if isinstance(args, str):
            args = shlex.split(args)

        if not isinstance(args, list):
            err = True

        if not err:
            if var is not None and not isinstance(var, str):
                err = True
            if not all(isinstance(arg, str) for arg in args):
                err = True

        if err:
            raise TypeError(
                'args must be a string, a list of strings or a dictionary '
                'containing a single item')

        if len(args) < 1:
            raise ValueError('Empty command')

        self.var = var
        self.cmd = args[0]
        self.args = args[1:]

    def expand_args(self, environ):
        expanded_args = []

        for arg in self.args:
            expanded = ''

            while arg:
                match = _var_re.search(arg)
                if match is None:
                    expanded += arg
                    break
                start, end = match.span()
                expanded += arg[:start]
                var = match.group(1)
                if var[0] == '{':
                    var = var[1:-1]
                expanded += environ.get(var, '')
                arg = arg[end+1:]

            expanded_args.append(expanded)

        return expanded_args

    def run(self, environ=None):
        if environ is None:
            environ = {}

        args = ['docker', '--host', self.swarm.address, self.cmd]
        args += self.expand_args(environ)
        process = subprocess.run(
            args, input=b'', check=True, stdout=subprocess.PIPE)
        output = process.stdout.decode().strip()

        if self.var is not None:
            environ[self.var] = output

        return output


class SwarmProcedureRunner(SwarmMixin, ProcedureRunner):

    def prepare(self):
        super().prepare()

        commands = self.procedure.content.get('run', [])
        if not isinstance(commands, list):
            raise StormValidationError(
                'run is expected to be a list of commands')

        self.commands = [
            DockerCommand(self.swarm, item) for item in commands]

    def run(self):
        environ = dict(self.job.params)
        for command in self.commands:
            command.run(environ)


class SwarmProcedureExecutor(
        SwarmMixin, ProcedureExecutor, GeventJobsExecutor):

    def get_pending_jobs(self):
        qs = super().get_pending_jobs()
        return qs.filter(target=self.swarm.cluster_id)

    def get_procedure_runner(self, agent, job):
        return SwarmProcedureRunner(self.swarm, agent, job)


class SwarmClusterProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-cluster'

    def get_snapshots(self):
        data = self.swarm.get_json('info')
        # Remove SystemTime to avoid unnecessary updates
        del data['SystemTime']
        return [data]

    def get_internal_id(self, data):
        return data['Swarm']['Cluster']['ID']

    def model_resource(self, data):
        return Resource(
            names=[
                data['Swarm']['Cluster']['Spec']['Name'],
                data['Swarm']['Cluster']['ID'],
            ],
            status='running',
            health='healthy',
        )


class SwarmServiceProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-service'

    def get_snapshots(self):
        return self.swarm.get_json('services')

    def get_internal_id(self, data):
        return data['ID']

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            names=[
                data['Spec']['Name'],
                data['ID'],
            ],
            status='running',
            health='healthy',
        )


class SwarmTaskProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-task'

    def __init__(self, executor, *args, **kwargs):
        self.executor = executor
        super().__init__(*args, **kwargs)

    def get_snapshots(self):
        return self.swarm.get_json('tasks')

    def get_internal_id(self, data):
        return data['ID']

    def get_task_names(self, data):
        names = []

        try:
            service_id = data['ServiceID']
            service_data = self.executor.snapshots[service_id].data
            service_name = service_data['Spec']['Name']
        except KeyError:
            service_name = None

        if service_name:
            task_name_suffix = (
                str(data['Slot']) if 'Slot' in data else data['NodeID'])
            task_name = '.'.join((service_name, task_name_suffix))

            names.append(task_name)
            names.append('.'.join((task_name, data['ID'])))

        names.append(data['ID'])

        try:
            names.append(data['Status']['ContainerStatus']['ContainerID'])
        except KeyError:
            pass

        return names

    def get_task_image(self, data):
        match = _image_re.match(data['Spec']['ContainerSpec']['Image'])
        repository, name, tag, digest = match.groups()

        if not repository:
            repository = 'library'
        if not tag:
            tag = 'latest'

        image = '{}/{}:{}'.format(repository, name, tag)

        if digest:
            image += '@' + digest

        return image

    def get_task_status(self, data):
        docker2storm_status = {
            'new': 'created',
            'allocated': 'created',
            'pending': 'starting',
            'assigned': 'starting',
            'accepted': 'starting',
            'preparing': 'starting',
            'ready': 'starting',
            'starting': 'starting',
            'running': 'running',
            'complete': 'stopped',
            'shutdown': 'removing',
            'failed': 'error',
            'rejected': 'error',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def model_resource(self, data):
        return Resource(
            parent=data['ServiceID'],
            names=self.get_task_names(data),
            image=self.get_task_image(data),
            status=self.get_task_status(data),
            health='healthy',
        )


class SwarmNodeProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-node'

    def get_snapshots(self):
        return self.swarm.get_json('nodes')

    def get_internal_id(self, data):
        return data['ID']

    def get_node_status(self, data):
        docker2storm_status = {
            'disconnected': 'stopped',
            'down': 'stopped',
            'ready': 'running',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            names=[
                data['Description']['Hostname'],
                data['ID'],
            ],
            status=self.get_node_status(data),
            health='healthy',
        )


class SwarmDiscoveryExecutor(SwarmMixin, DiscoveryExecutor):

    def get_probes(self):
        return [
            SwarmClusterProbe(self.swarm),
            SwarmServiceProbe(self.swarm),
            SwarmTaskProbe(self, self.swarm),
            SwarmNodeProbe(self.swarm),
        ]


class SwarmClient(AgentClient):

    def add_arguments(self, parser):
        super().add_arguments(parser)
        parser.add_argument(
            '-H', '--host', metavar='HOST[:PORT]', required=True,
            help='Docker daemon to connect to')

    def get_agent(self):
        self.swarm = Swarm(self.options.host)

        data = self.swarm.get_json('info')
        cluster_id = data['Swarm']['Cluster']['ID']

        return Agent(type='swarm', name='swarm-' + cluster_id)

    def run(self):
        executor = GeventPipelineExecutor(
            jobs=[
                SwarmDiscoveryExecutor(swarm=self.swarm, agent=self.agent),
                SwarmProcedureExecutor(swarm=self.swarm, agent=self.agent),
            ],
            restart_jobs=True)

        executor()


if __name__ == '__main__':
    SwarmClient().main()
