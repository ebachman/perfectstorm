#!/usr/bin/env python3

import gevent.monkey
gevent.monkey.patch_all()
# Prevent 'KeyboardInterrupt' lines from being printed
# on standard error
gevent.get_hub().NOT_ERROR += (KeyboardInterrupt,)

import collections  # noqa: E402
import functools  # noqa: E402
import re  # noqa: E402
import shlex  # noqa: E402
import subprocess  # noqa: E402
import urllib.parse  # noqa: E402

import requests  # noqa: E402

from stormlib import Agent, Resource, Group, events  # noqa: E402
from stormlib.cli import AgentClient  # noqa: E402
from stormlib.exceptions import StormValidationError  # noqa: E402
from stormlib.executors import (  # noqa: E402
    PollingExecutor,
    AgentExecutorMixin,
    DiscoveryExecutor,
    DiscoveryProbe,
    GeventJobsExecutor,
    GeventPipelineExecutor,
    ProcedureExecutor,
    ProcedureRunner,
)


_var_re = re.compile(r'(?<!\$)\$(\w+|{[^}]*})')
_image_re = re.compile(r'^(?:([^/:@]+)/)?([^/:@]+)(?::([^/:@]+))?(?:@([^/@]+))?$')


class Swarm:

    def __init__(self, address):
        self.address = address
        self._cluster_id = None

    def get(self, path):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.get(url)
        response.raise_for_status()
        return response

    def post(self, path, **kwargs):
        url = 'http://{}/{}'.format(self.address, path)
        response = requests.post(url, **kwargs)
        response.raise_for_status()
        return response

    @property
    def cluster_id(self):
        if self._cluster_id is None:
            data = self.get('info').json()
            self._cluster_id = data['Swarm']['Cluster']['ID']
        return self._cluster_id


class SwarmMixin:

    def __init__(self, swarm, *args, **kwargs):
        self.swarm = swarm
        super().__init__(*args, **kwargs)


class DockerCommand(SwarmMixin):

    def __init__(self, swarm, args):
        super().__init__(swarm=swarm)

        var = None
        err = False

        if isinstance(args, dict):
            if len(args) == 1:
                var, args = args.popitem()

        if isinstance(args, str):
            args = shlex.split(args)

        if not isinstance(args, list):
            err = True

        if not err:
            if var is not None and not isinstance(var, str):
                err = True
            if not all(isinstance(arg, str) for arg in args):
                err = True

        if err:
            raise TypeError(
                'args must be a string, a list of strings or a dictionary '
                'containing a single item')

        if len(args) < 1:
            raise ValueError('Empty command')

        self.var = var
        self.cmd = args[0]
        self.args = args[1:]

    def expand_args(self, environ):
        expanded_args = []

        for arg in self.args:
            expanded = ''

            while arg:
                match = _var_re.search(arg)
                if match is None:
                    expanded += arg
                    break
                start, end = match.span()
                expanded += arg[:start]
                var = match.group(1)
                if var[0] == '{':
                    var = var[1:-1]
                expanded += environ.get(var, '')
                arg = arg[end+1:]

            expanded_args.append(expanded)

        return expanded_args

    def run(self, environ=None):
        if environ is None:
            environ = {}

        args = ['docker', '--host', self.swarm.address, self.cmd]
        args += self.expand_args(environ)
        process = subprocess.run(
            args, input=b'', check=True, stdout=subprocess.PIPE)
        output = process.stdout.decode().strip()

        if self.var is not None:
            environ[self.var] = output

        return output


class SwarmProcedureRunner(SwarmMixin, ProcedureRunner):

    def prepare(self):
        super().prepare()

        commands = self.procedure.content.get('run', [])
        if not isinstance(commands, list):
            raise StormValidationError(
                'run is expected to be a list of commands')

        self.commands = [
            DockerCommand(self.swarm, item) for item in commands]

    def run(self):
        environ = dict(self.job.params)
        for command in self.commands:
            command.run(environ)


class SwarmProcedureExecutor(
        SwarmMixin, ProcedureExecutor, GeventJobsExecutor):

    def get_pending_jobs(self):
        qs = super().get_pending_jobs()
        return qs.filter(target=self.swarm.cluster_id)

    def get_procedure_runner(self, agent, job):
        return SwarmProcedureRunner(self.swarm, agent, job)


class SwarmClusterProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-cluster'

    def get_snapshots(self):
        data = self.swarm.get('info').json()
        # Remove SystemTime to avoid unnecessary updates
        del data['SystemTime']
        return [data]

    def get_internal_id(self, data):
        return data['Swarm']['Cluster']['ID']

    def model_resource(self, data):
        return Resource(
            names=[
                data['Swarm']['Cluster']['Spec']['Name'],
                data['Swarm']['Cluster']['ID'],
            ],
            status='running',
            health='healthy',
        )


class SwarmServiceProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-service'

    def get_snapshots(self):
        return self.swarm.get('services').json()

    def get_internal_id(self, data):
        return data['ID']

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            names=[
                data['Spec']['Name'],
                data['ID'],
            ],
            status='running',
            health='healthy',
        )


class SwarmTaskProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-task'

    def __init__(self, executor, *args, **kwargs):
        self.executor = executor
        super().__init__(*args, **kwargs)

    def get_snapshots(self):
        return self.swarm.get('tasks').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_task_names(self, data):
        names = []

        try:
            service_id = data['ServiceID']
            service_data = self.executor.snapshots[service_id].data
            service_name = service_data['Spec']['Name']
        except KeyError:
            service_name = None

        if service_name:
            task_name_suffix = (
                str(data['Slot']) if 'Slot' in data else data['NodeID'])
            task_name = '.'.join((service_name, task_name_suffix))

            names.append(task_name)
            names.append('.'.join((task_name, data['ID'])))

        names.append(data['ID'])

        try:
            names.append(data['Status']['ContainerStatus']['ContainerID'])
        except KeyError:
            pass

        return names

    def get_task_image(self, data):
        match = _image_re.match(data['Spec']['ContainerSpec']['Image'])
        repository, name, tag, digest = match.groups()

        if not repository:
            repository = 'library'
        if not tag:
            tag = 'latest'

        image = '{}/{}:{}'.format(repository, name, tag)

        if digest:
            image += '@' + digest

        return image

    def get_task_status(self, data):
        docker2storm_status = {
            'new': 'created',
            'allocated': 'created',
            'pending': 'starting',
            'assigned': 'starting',
            'accepted': 'starting',
            'preparing': 'starting',
            'ready': 'starting',
            'starting': 'starting',
            'running': 'running',
            'complete': 'stopped',
            'shutdown': 'removing',
            'failed': 'error',
            'rejected': 'error',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def model_resource(self, data):
        return Resource(
            parent=data['ServiceID'],
            names=self.get_task_names(data),
            image=self.get_task_image(data),
            status=self.get_task_status(data),
            health='healthy',
        )


class SwarmNodeProbe(SwarmMixin, DiscoveryProbe):

    resource_type = 'swarm-node'

    def get_snapshots(self):
        return self.swarm.get('nodes').json()

    def get_internal_id(self, data):
        return data['ID']

    def get_node_status(self, data):
        docker2storm_status = {
            'disconnected': 'stopped',
            'down': 'stopped',
            'ready': 'running',
        }

        return docker2storm_status.get(data['Status']['State'], 'unknown')

    def model_resource(self, data):
        return Resource(
            parent=self.swarm.cluster_id,
            names=[
                data['Description']['Hostname'],
                data['ID'],
            ],
            status=self.get_node_status(data),
            health='healthy',
        )


class SwarmDiscoveryExecutor(SwarmMixin, DiscoveryExecutor):

    def get_probes(self):
        return [
            SwarmClusterProbe(self.swarm),
            SwarmServiceProbe(self.swarm),
            SwarmTaskProbe(self, self.swarm),
            SwarmNodeProbe(self.swarm),
        ]


class SwarmNodeLabelingExecutor(
        SwarmMixin, AgentExecutorMixin, PollingExecutor, GeventJobsExecutor):

    # XXX It is possible to create groups with a query that excludes
    # XXX members of the group itself. Example:
    # XXX
    # XXX   group:
    # XXX     query:
    # XXX       snapshot.Spec.Labels.storm-grouped: { $exists: false }
    # XXX
    # XXX This will result in an infinite label/unlabel loop:
    # XXX
    # XXX - during the first iteration, all resources without a
    # XXX   'storm-grouped' label will be labelled;
    # XXX - at the second iteration the same resources will be no
    # XXX   longer part of the group, and will lose their label;
    # XXX - at this point we are back to our initial conditions:
    # XXX   the label will be applied again, then removed, and so on...

    def get_labeling(self):
        labels = collections.defaultdict(list)

        named_groups = Group.objects.filter(name={'$exists': True})

        for group in named_groups:
            relevant_members = group.members().filter(
                type={'$in': ('swarm-service', 'swarm-node')},
                owner=self.agent.id,
            )

            for res in relevant_members:
                labels[res.id].append(group.name)

        # Get all the resources that have 'storm-grouped' label, but that
        # do not belong to any group. Those will have their label removed.
        extra_labels = Resource.objects.filter(**{
            'id': {'$nin': list(labels)},
            'type': {'$in': ('swarm-service', 'swarm-node')},
            'owner': self.agent.id,
            'snapshot.Spec.Labels.storm-grouped': {'$exists': True},
        })

        for res in extra_labels:
            labels[res.id] = []

        return labels

    def poll_jobs(self):
        event_filter = events.EventFilter([
            events.EventMask(event_type='created', entity_type='resource'),
            events.EventMask(event_type='updated', entity_type='resource'),
            events.EventMask(event_type='created', entity_type='group'),
            events.EventMask(event_type='updated', entity_type='group'),
            events.EventMask(event_type='deleted', entity_type='group'),
        ])

        with event_filter(events.stream()) as stream:
            while True:
                labeling = self.get_labeling()
                if labeling:
                    break
                next(stream)

        return [
            functools.partial(self.assign_labels, res_id, group_names)
            for res_id, group_names in labeling.items()
        ]

    def assign_labels(self, res_id, group_names):
        res = Resource.objects.get(res_id)

        spec = res.snapshot['Spec']
        labels = spec['Labels']

        new_labels = {
            key: value for key, value in labels.items()
            if not key.startswith('storm-group')
        }

        if group_names:
            new_labels['storm-grouped'] = 'yes'
            for name in group_names:
                new_labels['storm-group-' + name] = 'yes'

        if labels == new_labels:
            return

        spec['Labels'] = new_labels

        if res.type == 'swarm-service':
            update_type = 'services'
        elif res.type == 'swarm-node':
            update_type = 'nodes'
        else:
            raise RuntimeError(res.type)
        update_id = urllib.parse.quote(res.snapshot['ID'])
        update_version = res.snapshot['Version']['Index']

        self.swarm.post(
            '{}/{}/update'.format(update_type, update_id),
            params={'version': update_version},
            json=spec)


class SwarmClient(AgentClient):

    def add_arguments(self, parser):
        super().add_arguments(parser)
        parser.add_argument(
            '-H', '--host', metavar='HOST[:PORT]', required=True,
            help='Docker daemon to connect to')
        parser.add_argument(
            '-p', '--with-procedure-runner', action='store_true',
            help='Run Swarm procedures submitted to this cluster')
        parser.add_argument(
            '-l', '--with-auto-labeling', action='store_true',
            help='Enable automatic labeling of services and nodes')

    def get_agent(self):
        self.swarm = Swarm(self.options.host)

        data = self.swarm.get('info').json()
        cluster_id = data['Swarm']['Cluster']['ID']

        return Agent(
            type='swarm',
            name='swarm-' + cluster_id,
            options={
                'autoLabeling': self.options.with_auto_labeling,
                'procedureRunner': self.options.with_procedure_runner,
            },
        )

    def run(self):
        jobs = [
            SwarmDiscoveryExecutor(swarm=self.swarm, agent=self.agent),
        ]

        if self.options.with_procedure_runner:
            jobs.append(SwarmProcedureExecutor(
                swarm=self.swarm, agent=self.agent))

        if self.options.with_auto_labeling:
            jobs.append(SwarmNodeLabelingExecutor(
                swarm=self.swarm, agent=self.agent))

        executor = GeventPipelineExecutor(jobs=jobs, restart_jobs=True)
        executor()


if __name__ == '__main__':
    SwarmClient().main()
